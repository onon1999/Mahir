{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMg7/LEzJpNRi67beNhyVVY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["nltk.download('punkt')\n","import os\n","import nltk\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from google.colab import files\n","# Import the files module from google.colab\n","\n","# Download the 'punkt' tokenizer models\n","nltk.download('punkt')\n","\n","!pip install pandas\n","import pandas as pd\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V0KLrQocRDkb","executionInfo":{"status":"ok","timestamp":1719211344756,"user_tz":-360,"elapsed":6650,"user":{"displayName":"Mahir Tajwar","userId":"07946050608390516943"}},"outputId":"8d7109cf-2f90-4b4e-fc84-741f2de45750"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}]},{"source":["import nltk # Import the nltk library first\n","\n","nltk.download('punkt') # Now you can use the nltk library\n","import os\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from google.colab import files\n","# Import the files module from google.colab\n","\n","\n","!pip install pandas\n","import pandas as pd"],"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RLiEFdx27FI","executionInfo":{"status":"ok","timestamp":1719211358124,"user_tz":-360,"elapsed":13390,"user":{"displayName":"Mahir Tajwar","userId":"07946050608390516943"}},"outputId":"1952616f-8c4f-4119-de9e-fa1e5da1e8fa"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"]}]},{"cell_type":"code","source":["\n","\n","import nltk\n","\n","import re\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from google.colab import files  # Import the files module from google.colab\n","\n","# Download the 'punkt' tokenizer models\n","nltk.download('punkt')\n","\n","# Load stop words\n","stop_words_files = [\n","    '/content/StopWords_Auditor.txt',\n","    '/content/StopWords_Currencies.txt',\n","    '/content/StopWords_DatesandNumbers.txt',\n","    '/content/StopWords_Generic.txt',\n","    '/content/StopWords_GenericLong.txt',\n","    '/content/StopWords_Names.txt',\n","    '/content/StopWords_Geographic.txt',\n","]\n","\n","stop_words = set()\n","for file in stop_words_files:\n","    with open(file, 'r', encoding='utf-8', errors='ignore') as f:\n","        stop_words.update(f.read().split())\n","\n","# Load positive and negative words\n","positive_words = set()\n","negative_words = set()\n","\n","with open('/content/positive-words.txt', 'r', encoding='utf-8', errors='ignore') as f:\n","    positive_words.update(f.read().split())\n","\n","with open('/content/negative-words.txt', 'r', encoding='utf-8', errors='ignore') as f:\n","    negative_words.update(f.read().split())\n","\n","# Remove stop words from positive and negative words\n","positive_words -= stop_words\n","negative_words -= stop_words\n","\n","def clean_text(text):\n","    tokens = word_tokenize(text)\n","    return [word.lower() for word in tokens if word.lower() not in stop_words and word.isalpha()]\n","\n","def calculate_scores(text):\n","    tokens = clean_text(text)\n","    positive_score = sum(1 for word in tokens if word in positive_words)\n","    negative_score = sum(-1 for word in tokens if word in negative_words)\n","\n","    polarity_score = (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n","    subjectivity_score = (positive_score + negative_score) / (len(tokens) + 0.000001)\n","\n","    return {\n","        'Positive Score': positive_score,\n","        'Negative Score': -negative_score,\n","        'Polarity Score': polarity_score,\n","        'Subjectivity Score': subjectivity_score\n","    }\n","\n","def count_syllables(word):\n","    word = word.lower()\n","    syllable_count = 0\n","    vowels = \"aeiou\"\n","    if word[0] in vowels:\n","        syllable_count += 1\n","    for index in range(1, len(word)):\n","        if word[index] in vowels and word[index - 1] not in vowels:\n","            syllable_count += 1\n","    if word.endswith(\"es\") or word.endswith(\"ed\"):\n","        syllable_count -= 1\n","    if syllable_count == 0:\n","        syllable_count = 1\n","    return syllable_count\n","\n","def analyze_readability(text):\n","    sentences = sent_tokenize(text)\n","    words = clean_text(text)\n","    num_sentences = len(sentences)\n","    num_words = len(words)\n","    num_complex_words = sum(1 for word in words if count_syllables(word) > 2)\n","\n","    avg_sentence_length = num_words / num_sentences\n","    percentage_complex_words = num_complex_words / num_words\n","    fog_index = 0.4 * (avg_sentence_length + percentage_complex_words)\n","\n","    avg_words_per_sentence = num_words / num_sentences\n","    word_count = num_words\n","    syllable_count = sum(count_syllables(word) for word in words)\n","\n","    personal_pronouns = len(re.findall(r'\\b(I|we|my|ours|us)\\b', text, re.I))\n","    avg_word_length = sum(len(word) for word in words) / num_words\n","\n","    return {\n","        'Average Sentence Length': avg_sentence_length,\n","        'Percentage of Complex Words': percentage_complex_words,\n","        'Fog Index': fog_index,\n","        'Average Number of Words Per Sentence': avg_words_per_sentence,\n","        'Complex Word Count': num_complex_words,\n","        'Word Count': word_count,\n","        'Syllable Count Per Word': syllable_count / num_words,\n","        'Personal Pronouns': personal_pronouns,\n","        'Average Word Length': avg_word_length\n","    }\n","\n","import requests\n","from bs4 import BeautifulSoup\n","\n","def scrape_website(url):\n","    try:\n","        # Fetch the HTML content of the webpage\n","        response = requests.get(url)\n","        if response.status_code == 200:\n","            soup = BeautifulSoup(response.content, 'html.parser')\n","            # Extracting article title\n","            article_title = soup.find('title').get_text()\n","            # Extracting article text\n","            article_text = \"\"\n","            for paragraph in soup.find_all('p'):\n","                article_text += paragraph.get_text() + \" \"\n","            return article_title, article_text\n","        else:\n","            print(\"Failed to fetch the webpage. Status code:\", response.status_code)\n","            return None, None\n","    except Exception as e:\n","        print(\"An error occurred during web scraping:\", str(e))\n","        return None, None\n","\n","\n","def upload_and_analyze_file():\n","    url = input(\"Enter the URL of the article: \")\n","    article_title, article_text = scrape_website(url)\n","    if article_title and article_text:\n","        print(f'Analyzing article: {article_title}')\n","        sentiment_scores = calculate_scores(article_text)\n","        readability_scores = analyze_readability(article_text)\n","        print('Sentiment Scores:', sentiment_scores)\n","        print('Readability Scores:', readability_scores)\n","\n","\n","\n","def upload_and_analyze_file():\n","    url = input(\"Enter the URL of the article: \")\n","    article_title, article_text = scrape_website(url)\n","    if article_title and article_text:\n","\n","        sentiment_scores = calculate_scores(article_text)\n","        readability_scores = analyze_readability(article_text)\n","        print('Sentiment Scores:', sentiment_scores)\n","        print('Readability Scores:', readability_scores)\n","\n","\n","def upload_and_analyze_file():\n","    url = input(\"Enter the URL of the article: \")\n","    article_title, article_text = scrape_website(url)\n","    if article_title and article_text:\n","        print(f'Analyzing article: {article_title}')\n","        sentiment_scores = calculate_scores(article_text)\n","        readability_scores = analyze_readability(article_text)\n","        print('Sentiment Scores:', sentiment_scores)\n","        print('Readability Scores:', readability_scores)\n","\n","        # Check if the Excel file already exists\n","        if os.path.exists('article_analysis.xlsx'):\n","            # Load the existing Excel file\n","            df = pd.read_excel('article_analysis.xlsx')\n","            # Append new data to the DataFrame\n","            new_data = {\n","                'URL': url,\n","                'Article Title': article_title,\n","                'Positive Score': sentiment_scores['Positive Score'],\n","                'Negative Score': sentiment_scores['Negative Score'],\n","                'Polarity Score': sentiment_scores['Polarity Score'],\n","                'Subjectivity Score': sentiment_scores['Subjectivity Score'],\n","                'Average Sentence Length': readability_scores['Average Sentence Length'],\n","                'Percentage of Complex Words': readability_scores['Percentage of Complex Words'],\n","                'Fog Index': readability_scores['Fog Index'],\n","                'Average Number of Words Per Sentence': readability_scores['Average Number of Words Per Sentence'],\n","                'Complex Word Count': readability_scores['Complex Word Count'],\n","                'Word Count': readability_scores['Word Count'],\n","                'Syllable Count Per Word': readability_scores['Syllable Count Per Word'],\n","                'Personal Pronouns': readability_scores['Personal Pronouns'],\n","                'Average Word Length': readability_scores['Average Word Length']\n","            }\n","\n","def upload_and_analyze_file():\n","    url = input(\"Enter the URL of the article: \")\n","    article_title, article_text = scrape_website(url)\n","    if article_title and article_text:\n","        print(f'Analyzing article: {article_title}')\n","        sentiment_scores = calculate_scores(article_text)\n","        readability_scores = analyze_readability(article_text)\n","        print('Sentiment Scores:', sentiment_scores)\n","        print('Readability Scores:', readability_scores)\n","\n","        # Check if the Excel file already exists\n","        if os.path.exists('article_analysis.xlsx'):\n","            # Load the existing Excel file\n","            df_existing = pd.read_excel('article_analysis.xlsx')\n","            # Create a DataFrame with the new data\n","            new_data = {\n","                'URL': url,\n","                'Article Title': article_title,\n","                'Positive Score': sentiment_scores['Positive Score'],\n","                'Negative Score': sentiment_scores['Negative Score'],\n","                'Polarity Score': sentiment_scores['Polarity Score'],\n","                'Subjectivity Score': sentiment_scores['Subjectivity Score'],\n","                'Average Sentence Length': readability_scores['Average Sentence Length'],\n","                'Percentage of Complex Words': readability_scores['Percentage of Complex Words'],\n","                'Fog Index': readability_scores['Fog Index'],\n","                'Average Number of Words Per Sentence': readability_scores['Average Number of Words Per Sentence'],\n","                'Complex Word Count': readability_scores['Complex Word Count'],\n","                'Word Count': readability_scores['Word Count'],\n","                'Syllable Count Per Word': readability_scores['Syllable Count Per Word'],\n","                'Personal Pronouns': readability_scores['Personal Pronouns'],\n","                'Average Word Length': readability_scores['Average Word Length']\n","            }\n","\n","            df_new = pd.DataFrame(new_data, index=[0])\n","            # Concatenate the existing DataFrame with the new data\n","            df = pd.concat([df_existing, df_new], ignore_index=True)\n","        else:\n","            # If the Excel file doesn't exist, create a new DataFrame with the new data\n","            df = pd.DataFrame({\n","                'URL': [url],\n","                'Article Title': [article_title],\n","                'Positive Score': [sentiment_scores['Positive Score']],\n","                'Negative Score': [sentiment_scores['Negative Score']],\n","                'Polarity Score': [sentiment_scores['Polarity Score']],\n","                'Subjectivity Score': [sentiment_scores['Subjectivity Score']],\n","                'Average Sentence Length': [readability_scores['Average Sentence Length']],\n","                'Percentage of Complex Words': [readability_scores['Percentage of Complex Words']],\n","                'Fog Index': [readability_scores['Fog Index']],\n","                'Average Number of Words Per Sentence': [readability_scores['Average Number of Words Per Sentence']],\n","                'Complex Word Count': [readability_scores['Complex Word Count']],\n","                'Word Count': [readability_scores['Word Count']],\n","                'Syllable Count Per Word': [readability_scores['Syllable Count Per Word']],\n","                'Personal Pronouns': [readability_scores['Personal Pronouns']],\n","                'Average Word Length': [readability_scores['Average Word Length']]\n","            })\n","\n","        # Write DataFrame to Excel file\n","        df.to_excel('article_analysis.xlsx', index=False)\n","        print(\"Analysis saved to 'article_analysis.xlsx'\")\n","    else:\n","        print(\"Failed to scrape the article.\")\n","\n","# Call the function to input URL and analyze the article\n","upload_and_analyze_file()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yVe7-Su2fpRH","executionInfo":{"status":"ok","timestamp":1719211392108,"user_tz":-360,"elapsed":8719,"user":{"displayName":"Mahir Tajwar","userId":"07946050608390516943"}},"outputId":"cfefd022-121d-465a-f964-12138f1aa4ce"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Enter the URL of the article: https://insights.blackcoffer.com/rising-it-cities-and-its-impact-on-the-economy-environment-infrastructure-and-city-life-by-the-year-2040-2/\n","Analyzing article: Rising IT cities and its impact on the economy, environment, infrastructure, and city life by the year 2040. - Blackcoffer Insights\n","Sentiment Scores: {'Positive Score': 13, 'Negative Score': 2, 'Polarity Score': 1.3636362396694328, 'Subjectivity Score': 0.038194444311824845}\n","Readability Scores: {'Average Sentence Length': 9.931034482758621, 'Percentage of Complex Words': 0.375, 'Fog Index': 4.122413793103449, 'Average Number of Words Per Sentence': 9.931034482758621, 'Complex Word Count': 108, 'Word Count': 288, 'Syllable Count Per Word': 2.361111111111111, 'Personal Pronouns': 6, 'Average Word Length': 7.069444444444445}\n","Analysis saved to 'article_analysis.xlsx'\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"rclx5pdEbrwR"}}]}